\section{Multiple Choice}
\begin{tiny}
    Seien $A1$, $A2$, $A3 \in \mathcal{F}$ paarweise unabhängige Ereignisse. Welche Aussage ist korrekt?
    \begin{itemize}
        \item[\checkmark] Die Ereignisse $A1$, $A2$, $A3$ sind nicht zwangsläufig unabhängig.
        \item[$\square$] Die Ereignisse $A1$, $A2$, $A3$ sind zwangsläufig unabhängig.
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Seien $A$, $B$ zwei Ereignisse. $P[A \cup B] = P[A] + P[B]$ gilt, falls:
    \begin{itemize}
        \item[$\square$] $A$, $B$ unabhängig sind.
        \item[\checkmark] $A$, $B$ disjunkt sind.
        \item[$\square$] $A$ eine Teilmenge von $B$ ist.
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Seien $A$, $B$, $C$ Ereignisse. Welche der folgenden Aussagen ist wahr?
    \begin{itemize}
        \item[$\square$] Falls $A$, $B$ sowie $A$, $C$ unabhängig sind, so sind auch $A$, $B \cap C$ unabhängig.
        \item[$\square$] Falls $A$, $B$ sowie $B$, $C$ unabhängig sind, so sind auch $A$, $C$ unabhängig.
        \item[\checkmark] Falls $A$, $B$ und $C$ unabhängig sind, so sind auch $A$, $B \cap C$ unabhängig.
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Seien $X$, $Y$ reelle Zufallsvariablen. Welche Aussage ist im Allgemeinen falsch?
    \begin{itemize}
        \item[$\square$] $\text{Var}[X] \geq 0$
        \item[\checkmark] $\text{Var}[X + Y] = \text{Var}[X] + \text{Var}[Y]$
        \item[$\square$] $\text{Var}[aX + b] = a^2 \text{Var}[X]$
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Für stetige Zufallsvariablen gilt immer:
    \begin{itemize}
        \item[\checkmark] Die Verteilungsfunktion ist stetig.
        \item[$\square$] Die Dichtefunktion ist stetig.
        \item[$\square$] Weder noch.
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Für die Dichte ist eine gleichverteilte Zufallsvariable ein Gegenbeispiel.

    Seien $X$, $Y$ zwei Zufallsvariablen mit gemeinsamer Dichte $f_{X,Y}$. Welche Aussage ist korrekt?
    \begin{itemize}
        \item[\checkmark] $X$, $Y$ sind immer stetig.
        \item[$\square$] Die Zufallsvariablen sind nicht notwendigerweise stetig.
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Sei $Z = (X, Y)$ eine $\mathbb{R}^2$-wertige Zufallsvariable mit Dichte:
    \[ f_Z (x, y) = \frac{1}{2\pi} e^{-\frac{1}{2} (x^2 + y^2)} \]

    Welche Aussage ist korrekt?
    \begin{itemize}
        \item[$\square$] $X$ und $Y$ sind korreliert und nicht unabhängig.
        \item[$\square$] $X$ und $Y$ sind unkorreliert und nicht unabhängig.
        \item[\checkmark] $X$ und $Y$ sind unkorreliert und unabhängig.
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Sei $X$ eine reellwertige Zufallsvariable mit Dichte $f_X$ und Verteilungsfunktion $F_X$. Welche der Aussagen ist im Allgemeinen falsch?
    \begin{itemize}
        \item[$\square$] $F_X$ ist stetig.
        \item[\checkmark] $F_X$ ist strikt monoton wachsend.
        \item[$\square$] $P[a \leq X \leq b] = F_X(b) - F_X(a)$ für $-\infty < a \leq b < \infty$.
    \end{itemize}

    Seien $(X_i)_{i=1}^n$ uiv. Zufallsvariablen mit Verteilungsfunktion $F_{X_i} = F$. Was ist die Verteilungsfunktion von $M = \max(X_1, ..., X_n)$?
    \begin{itemize}
        \item[\checkmark] $F_M (a) = F(a)^n$
        \item[$\square$] $F_M (a) = 1 - F(a)^n$
        \item[$\square$] $F_M (a) = (1 - F(a))^n$
    \end{itemize}

    Sei $X$ eine Zufallsvariable mit $F_X$. Was gilt für $a < b$?
    \begin{itemize}
        \item[$\square$] $P[a < X < b] = F_X(b) - F_X(a)$
        \item[\checkmark] $P[a < X \leq b] = F_X(b) - F_X(a)$
        \item[$\square$] $P[a \leq X \leq b] = F_X(b) - F_X(a)$
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Sei $X \sim \text{Poisson}(\lambda)$, $\lambda > 0$, welche der Aussagen ist korrekt?
    \begin{itemize}
        \item[$\square$] $P[X > 5] = 1 - P[X < 5]$
        \item[\checkmark] $P[X \leq 1|X \geq 1] = \frac{\lambda}{1 + \lambda}$
        \item[$\square$] $2X \sim \text{Poisson}(2\lambda)$
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Sei $X \sim \text{Poisson}(\lambda)$, $\lambda > 0$, was ist $E[X^2]$?
    \begin{itemize}
        \item[$\square$] $\lambda$
        \item[$\square$] $\frac{1}{\lambda^2}$
        \item[\checkmark] $\lambda \cdot (\lambda + 1)$
        \item[$\square$] $\lambda^2$
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Es gilt $P[X > t + s | X > s] = P[X > t]$ für alle $t$, $s \geq 0$, falls
    \begin{itemize}
        \item[$\square$] $X \sim U([a, b])$
        \item[$\square$] $X \sim \text{Poisson}(\lambda)$
        \item[\checkmark] $X \sim \text{Exp}(\lambda)$ (Gedächtnislosigkeit)
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Seien $X$, $Y$ unabhängig und log-normalverteilt, d.h. $\ln X$, $\ln Y$ sind normalverteilt. Welche Aussage ist korrekt?
    \begin{itemize}
        \item[\checkmark] $XY$ ist log-normalverteilt.
        \item[$\square$] $XY$ ist normalverteilt.
        \item[$\square$] $e^{X+Y}$ ist normalverteilt.
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Sei $X \sim N(0, 1)$ und $Y \sim U[0, 1]$ ZV mit $\text{Cov}(X, Y) = 0$. Welche Aussage ist korrekt?
    \begin{itemize}
        \item[$\square$] $X$, $Y$ unabhängig sind.
        \item[\checkmark] $E[XY] = 0$
        \item[$\square$] Keine der beiden anderen Aussagen ist wahr.
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Sei $(X_i)_{i=1}^n$ uiv. $\sim N(0, 1)$. Sei $\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i$. Dann gilt:
    \begin{itemize}
        \item[$\square$] $\bar{X} \overset{n \to \infty}{\longrightarrow} \mu$ in Wahrscheinlichkeit.
        \item[$\square$] $\bar{X} \overset{n \to \infty}{\longrightarrow} \mu$ P-fastsicher.
        \item[\checkmark] Im Allgemeinen sind 1. und 2. falsch.
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Falls zu einem gegebenen Test die Hypothese auf dem 2.5%-Niveau abgelehnt wird, dann:
    \begin{itemize}
        \item[\checkmark] Wird sie auch auf dem 5%-Niveau abgelehnt.
        \item[$\square$] Wird sie auch auf dem 1%-Niveau abgelehnt.
        \item[$\square$] Im Allgemeinen kann nicht behauptet werden, dass sie auf einem höheren oder tieferen Niveau auch abgelehnt wird.
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Seien $X$, $Y$ Zufallsvariablen mit gemeinsamer Dichte $f_{X,Y}$. Welche Aussage ist korrekt?
    \begin{itemize}
        \item[$\square$] Die ZV $X$, $Y$ sind nicht notwendigerweise stetig, dies hängt von $f_{X,Y}$ ab.
        \item[\checkmark] Die ZV $X$, $Y$ sind immer stetig.
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Wir betrachten die gemeinsame Verteilung von zwei diskreten Zufallsvariablen $X$, $Y$. Welche Aussagen sind korrekt?
    \begin{itemize}
        \item[$\square$] Aus den einzelnen Gewichtsfunktionen kann man immer die gemeinsame Gewichtsfunktion berechnen.
        \item[$\square$] Aus den einzelnen Gewichtsfunktionen und $\text{Cov}(X, Y)$ kann man immer die gemeinsame Gewichtsfunktion berechnen.
        \item[\checkmark] Aus der gemeinsamen Gewichtsfunktion kann man immer die einzelnen Gewichtsfunktionen berechnen.
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Seien $(X_i)_{i=1}^n$ uiv. $\sim N(0, 1)$. Welche Aussagen sind korrekt?
    \begin{itemize}
        \item[\checkmark] $X_1^2 + \dots + X_n^2 \sim \chi^2_n$
        \item[\checkmark] $\frac{1}{n}(X_1 + \dots + X_n)^2 \sim \chi^2_n$
        \item[$\square$] $(X_1 + \dots + X_n)^2 \sim \chi^2_n$
        \item[\checkmark] $X_1^2 + X_2^2 \sim \text{Exp}(1/2)$
    \end{itemize}
    \rule{\linewidth}{0.4pt}

    Wenn das Signifikanzniveau $\alpha$ eines Tests kleiner wird, dann:
    \begin{itemize}
        \item[$\square$] Wird der Verwerfungsbereich für die Nullhypothese größer.
        \item[$\square$] Wird die Macht des Tests größer.
        \item[\checkmark] Wird die Wahrscheinlichkeit für den Fehler 2. Art größer.
    \end{itemize}
    \rule{\linewidth}{0.4pt}
    Aufgabe: Um die Anzahl Fische $N$ in einem See zu bestimmen, gehen wir
    wie folgt vor: Zuerst werden 500 Fische gefangen und markiert. Danach
    werden wieder 200 Fische gefangen und die Anzahl $X$ der markierten
    Fische gezählt.

    \begin{enumerate}
        \item $X \sim \text{Bin}(n, \theta)$, wie groß ist $n$? Wie groß ist $\theta$, wenn die Gesamtzahl
              der Fische $N = 2000$ ist?

              $n = 200$, da wir 200 Fische herausziehen. $\theta = \frac{500}{2000} = \frac{1}{4}$.

        \item Die Beobachtung gibt einen Wert für $X$ von 40. Gib eine Schätzung
              für $\theta$ und eine Schätzung für $N$ ab.

              Wir schätzen $\theta$ mit $T = \frac{X}{n}$, der realisierte Schätzwert ist also $\hat{\theta} = \frac{40}{200} = \frac{1}{5}$. Wenn wir nun $\theta = \frac{500}{N}$ nach $N$ auflösen, erhalten wir $N = 2500$.

        \item Bestimme ein approximatives Konfidenzintervall für $\theta$ mit $\alpha = 0.05$.

              $T = X - n\theta$, $\sqrt{n\theta(1-\theta)} \approx \sqrt{n}\theta$.

              Aus dem zentralen Grenzwertsatz folgt daher
              \[
                  P_{\theta}\left[-1.96 \leq \frac{T}{\sqrt{n}\theta} \leq 1.96\right] \geq 0.95.
              \]
              Unter Verwendung von $\theta(1 - \theta) \leq \frac{1}{4}$ ergibt sich ein approximatives Vertrauensintervall für $\theta$ von:
              \[
                  \left[T - 1.96 \frac{\sqrt{\theta(1-\theta)}}{\sqrt{2n}}, T + 1.96 \frac{\sqrt{\theta(1-\theta)}}{\sqrt{2n}}\right] = [0.13, 0.27].
              \]
    \end{enumerate}
\end{tiny}
