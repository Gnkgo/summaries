\section*{Probability modeling}
Find $h:X\rightarrow Y$ that min. pred. error: 
$R(h) = \int P(x,y)l(y;h(x)) \partial yx \partial y = \mathbb{E}_{x,y}[l(y;h(x))]$

\subsection*{For least squares regression}
Best $h$: $h^*(x) = \mathbb{E}[Y|X=x]$ \\
Pred.: $\hat{y} = \hat{\mathbb{E}}[Y|X=\hat{x}] = \int \hat{P}(y|X=\hat{x}) y \partial y$

\subsection*{Maximum Likelihood Estimation (MLE)}
$\theta^* = \underset{\theta}{\operatorname{argmax}} ~ \hat{P}(y_1,\ldots,y_n|x_1,\ldots,x_n,\theta)$\\
E.g. lin. + Gauss: $y_i = w^T x_i + \varepsilon_i, \varepsilon_i \sim \mathcal{N}(0, \sigma^2)$\\
i.e. $y_i \sim \mathcal{N}(w^T x_i, \sigma^2)$, With MLE (use\\ $\operatorname{argmin} ~ - \operatorname{log}$): $w^* = \underset{w}{\operatorname{argmin}} \sum (y_i-w^{T}x_i)^2$

\subsection*{Bias/Variance/Noise}
Prediction error = $Bias^2 + Variance + Noise$

\subsection*{Maximum a posteriori estimate (MAP)}
Introduce bias o reduce variance. The small weight assumption is a Gaussian prior $w_i \in \mathcal{N}(0, \beta^2)$\\
Bay.: $P(w|x,y) = \frac{P(w|x) P(y|x,w)}{P(y|x)} = \frac{P(w) P(y|x,w)}{P(y|x)}$
Now we want to find MAP for $w$:
\begin{align*}
    \hat{w} &= argmax_w p(w | \bar{x}, \bar{y})\\
    &= argmin_w - \log{\frac{p(w) \cdot p(y | x, w)}{p(y|w)}} \\
    &= argmin_w \frac{\sigma^2}{\beta^2} ||w||^2_2 + \sum_{i=1}^n {(y_i - w^T x_i)}^2
\end{align*}
Regularization can be understood as MAP inference, with different priors (= regularizers) and likelihoods (= loss functions).
\subsection*{Logistic regression}
Link func.: $\sigma(w^{T}x) = \frac{1}{1+\exp(-w^{T}x)}$ (Sigmoid)\\
$P(y|x,w) = Ber(y; \sigma(w^{T}x)) = \frac{1}{1+\exp(-y w^T x)}$
Classification: Use $P(y|x,w)$, predict most likely class label.\\
MLE: $\underset{w}{\operatorname{argmax}} ~ P(y_{1:n}|w,x_{1:n})\\
\Rightarrow w^* = \underset{w}{\operatorname{argmin}} \sum_{i=1}^n \log(1+\exp(-y_i w^T x_i))$\\
SGD update: $w = w + \eta_t y x \hat{P}(Y = -y|w,x)$\\
$\hat{P}(Y = -y|w,x) = \frac{1}{1+\exp(yw^{T}x)}$\\
MAP: Gauss. prior $\Rightarrow ||w||_2^2$, Lap. p. $\Rightarrow||w||_1$\\
SGD: $w = w (1-2\lambda \eta_t) + \eta_t y x \hat{P}(Y = -y|w,x)$