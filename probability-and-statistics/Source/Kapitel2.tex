\subsection*{Diskrete Zufallsvariable}
Eine reelwertige diskrete Zufallsvariable auf $\Omega$ ist eine Funktion $X :
  \Omega \mapsto \R$. Mit $\Omega$ ist natürlich auch $\W (X) = \{x_1, x_2,
  \dots\}$ endlich oder abzählbar.
\begin{itemize}
  \item Die Verteilungsfunktion von $X$ ist die Abbildung $F_X : \R \mapsto [0, 1]$,
        definiert durch:
        \begin{align*}
          t \mapsto F_X (t) := P[X \leq t] := P[\{\omega : X (\omega) \leq t\}]
        \end{align*}
  \item Die Gewichtsfunktion oder diskrete Dichte von $X$ ist die Funktion $p_X : \W
          (X) \mapsto [0, 1]$, definiert durch:
        \begin{align*}
          p_X (X_k) := P[X = x_k] = P[\{\omega : X (\omega) = x_k\}]
        \end{align*}
\end{itemize}
Wobei gilt:
\begin{itemize}
  \item $F_X (t) = P[X \leq t] = \sum_{k \text{ mit } x_k \leq t} p_X (x_k)$
  \item Für jedes $x_k \in \W (X)$ gilt $0 \leq p_X (x_k) \leq 1$ und $\sum_{x_k \in \W
            (X)} p_X (x_k) = 1$
  \item $\mu_X (B) := P[X \in B] = \sum_{x_k \in B} p_X (x_k)$
  \item $\sum_{x_k \in \W (X)} p_X (x_k) = P[X \in \W (X)] = 1$
\end{itemize}
\subsection*{Indikatorfunktion}
Für jede Teilmenge $A \subseteq \Omega$ ist die Indikatorfunktion $I_A$ von $A$
definiert durch:
\begin{align*}
  I_A (\omega) :=
  \begin{cases}
    1 \quad \text{falls } \omega \in A             \\
    0 \quad \text{falls } \omega \in A^\complement \\
  \end{cases}
\end{align*}
\subsection*{Erwartungswert}
Sei $X$ eine diskrete Zufallsvariable mit Gewichtsfunktion $p_X (x)$, dann ist
der Erwartungswert definiert durch:
\begin{align*}
  E[X] := \sum_{x_k \in \W (X)} x_k \cdot p_X (x_k)
\end{align*}
und hat folgende Eigenschaften:
\begin{itemize}
  \item Linearität: $E[a \cdot X + b] = a \cdot E[X] + b$
  \item Monotonie: $X \leq Y \implies E[X] \leq E[Y]$
  \item Nimmt $X$ nur Werte in $\N $ an:
        \begin{align*}
          E[X] = \Sinfty P[X \geq i]
        \end{align*}
\end{itemize}
\subsection*{Erwartungswert von Funktionen}
Sei $X$ eine Diskrete Zufallsvariable mit Gewichtsfunktion $p_X (x)$ und $Y = g
  (X)$ für eine Funktion $Y: \R \mapsto \R$. Dann gilt:
\begin{align*}
  E[Y] = E[g (X)] = \sum_{x_k \in \W (X)} g (x_k) \cdot p_X (x_k)
\end{align*}
\subsection*{Varianz}
Sei $X$ eine diskrete Zufallsvariable. Ist $E[X^2] < \infty$, so heisst:
\begin{align*}
  Var[X] & := E[ {X - E[X]}^2]                                     \\
         & = \sum_{x_k \in \W (X)}  {x_k - E[X]}^2 \cdot p_X (x_k)
\end{align*}
die Varianz von $X$. Es gilt weiter:
\begin{itemize}
  \item $Var[X] = E[X^2] - {E[X]}^2$
  \item $Var[a \cdot X + b] = a^2 \cdot Var[X]$
  \item $Var[X - Y] = Var[X] +  {-1}^2 \cdot Var[Y]$
  \item $Var(X+Y) = Var(X) + Var(Y) + 2Cov(X,Y)$
\end{itemize}
\subsection*{Standardabweichung}
$$
  \sigma (X) = \sqrt{Var[X]}
$$
\subsection*{Gemeinsame Verteilung}
Seien $\zufallsvariablen$ beliebige Zufallsvariablen. Die Gemeinsame
Verteilungsfunktion von $\zufallsvariablen$ ist die Abbildung $F: \R^n \mapsto
  [0, 1]$, definiert durch:
\begin{align*}
  (x_1, \dots, x_n) \mapsto F (x_1, \dots, x_n) & := P[X_1 \leq x_1, \dots, X_n \leq x_n]                        \\
                                                & = \sum_{y_1 \leq x_1, \dots, y_n \leq x_n} p (y_1, \dots, y_n)
\end{align*}
Die Gemeinsame Gewichtsfunktion ist:
\begin{align*}
  p (x_1, \dots, x_n) := P[X_1 = x_1, \dots, X_n = x_n]
\end{align*}

\subsection*{Unabhängige Zufallsvariablen}
Zufallsvariablen $\zufallsvariablen$ heissen Unabhängig, falls gilt
(äquivalent):
\begin{align*}
  F (x_1, \dots, x_n) & = F_{X_1} (x_1) \cdot \hdots \cdot F_{X_n} (x_n) \\
  p (x_1, \dots, x_n) & = p_{X_1} (x_1) \cdot \hdots \cdot p_{X_n} (x_n)
\end{align*}
\subsection*{Unabhängige Ereignisse}
Ereignisse $\ereignisse$ heissen Unabhängig, falls für beliebige Teilmengen
$B_i \subseteq \W (X_i) \quad i = 1, \dots, n$ gilt (äquivalent):
\begin{align*}
  P[X_1 \in B_1, \dots, X_n \in B_n] = \Pn P[X_i \in B_i]
\end{align*}
\subsection*{Funktionen von Zufallsvariablen}
Seien $\zufallsvariablen$ diskrete Unabhängige Zufallsvariablen und $f_i: \R
  \mapsto \R$ irgendwelche Funktionen. Sei weiter $Y_i := f_i (X_i)$. Dann sind
die Zufallsvariablen $Y_1, \dots, Y_n$ ebenfalls unabhängig.
\subsection*{Linearität des Erwartungswertes}
Seien $\zufallsvariablen$ diskrete Zufallsvariablen mit endlichen
Erwartungswerten. $E[X_1], \dots, E[X_n]$. Sei $Y = a + \Sn b_i \cdot X_i$ mit
Konstanten $a, b_1, \dots, b_n$. Dann gilt:
\begin{align*}
  E[Y] = a + \Sn b_i \cdot E[X_i]
\end{align*}
\subsection*{Kovarianz}
Seien $X, Y$ Zufallsvariablen auf einem Wahrscheinlichkeitsraum $ (\Omega, \F,
  P)$ mit endlichen Erwartungswerten. Dann ist die Kovarianz definiert als:
\begin{align*}
  Cov (X, Y) & := E[XY] - E[X]E[Y]          \\
             & = E[ (X - E[X])  (Y - E[Y])]
\end{align*}
Wobei $Cov (X, X) = Var[X]$.
\subsection*{Korrelation}
Die Korrelation von $X, Y$ ist definiert durch
\begin{align*}
  \rho (X, Y) := \begin{cases}
                   \frac{Cov (X, Y)}{\sigma (X) \cdot \sigma (Y)} & \text{falls } \sigma (X) \cdot \sigma (Y) > 0 \\
                   0                                              & \text{sonst.}
                 \end{cases}
\end{align*}
und es gilt $\abs{Cov (X, Y)} \leq \sigma (X) \cdot \sigma (Y)$
beziehungsweise $-1 \leq \rho (X, Y) \leq 1$.
\subsection*{Summenformel für Varianzen}
\begin{align*}
  Var \left[ \Sn X_i \right] = \Sn Var[X_i] + 2 \cdot \sum_{i < j} Cov (X_i, X_j)
\end{align*}
ist aber $Cov (X, Y) = 0$  ($X, Y$ paarweise unkorreliert), so wird
die Summe linear.
\subsection*{Produkte von Zufallsvariablen}
Seien $\zufallsvariablen$ diskrete Zufallsvariablen mit endlichen
Erwartungswerten. Falls $\zufallsvariablen$ unabhängig sind, so ist:
\begin{align*}
  E \left[ \Pn X_i \right] = \Pn E[X_i]
\end{align*}
Dann sind auch $\zufallsvariablen$ paarweise unkorreliert und:
\begin{align*}
  Var \left[ \Sn X_i \right] = \Sn Var[X_i]
\end{align*}
da Unabhängig $\implies$ paarweise Unabhängig $\implies$ unkorreliert.
\subsection*{Bedingte Verteilung}
Seien $X, Y$ diskrete Zufallsvariablen mit gemeinsamer Gewichtsfunktion $p (x,
  y)$. Die bedingte Gewichtsfunktion von $X$, gegeben dass $Y = y$, ist definiert
durch:
\begin{align*}
  p_{X \, | \, Y} (x \; | \; y)    & := \cond{X = x}{Y = y}     \\
  \frac{P[X = x, Y = y]}{P[Y = y]} & = \frac{p (x, y)}{p_Y (y)}
\end{align*}
für $p_Y (y) > 0$ und $0$ sonst.
\subsection*{Kriterium für Unabhängigkeit}
$X, Y$ sind genau dann unabhängig, wenn für alle $y$ mit $p_Y (y) > 0$
gilt:
\begin{align*}
  p_{X\,|\,Y} (x \; | \; y) = p_X (x) &  & \forall x \in \W (X)
\end{align*}
\subsection*{$n$ tief $k$}
\begin{align*}
  \binom{n}{k} = \frac{n!}{k! \cdot  (n - k)!}
\end{align*}
