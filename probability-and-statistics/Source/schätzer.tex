% chktex-file 13
% chktex-file 12
% chktex-file 11

\section{Schätzer}
\subsection{Schätzer}
Wir suchen ein Modell für eine Stichprobe $\zufallsvariablen$ und haben einen
Parameteraum $\vartheta \subseteq \varTheta$ und für jedes $\vt$ einen
Wahrscheinlichkeitsraum $ (\Omega, \F, P_\vt)$. Wir möchten nun die Parameter
$\vt_1, \dots, \vt_m$ bestimmen. Ein Schätzer $T_j$ für einen Parameter $\vt_j$
ist eine Zufallsvariable der Form $T_j := t_j (\zufallsvariablen)$ für eine
Schätzfunktion $t_j$.
\begin{definition}{Schätzwert}
  Verschiedene $T_{\text{ML}}$
  \begin{equation*}
    \begin{array}{cc}
      \textbf{bern} (\theta)     & \frac{1}{n} \sum_{i=1}^{n} X_i = \overline{X}                                \\[5pt]
      \textbf{bin} (k,\theta)    & \frac{1}{nk} \sum_{i=1}^{n} X_i = \frac{1}{k} \overline{X}                   \\[5pt]
      \mathcal{P} (\theta)       & \frac{1}{n} \sum_{i=1}^{n} X_i = \overline{X}                                \\[5pt]
      \textbf{geom}(\theta)      & \frac{n}{\sum_{i=1}^{n} X_i} = \frac{1}{\overline{X}}                        \\[10pt]
      \mathcal{U}([a,b])         & \hat{a} = \min\{X_1, \ldots , X_n\} \quad \hat{b}= \max\{X_1, \ldots , X_n\} \\[5pt]
      \textbf{exp}(\theta)       & = \frac{n}{\sum_{i=1}^{n} X_i} \frac{1}{\overline{X}}                        \\[5pt]
      \mathcal{N}(\mu, \sigma^2) & \hat{\mu} = \overline{X}_n \quad \hat{\sigma}^2 = S^2
    \end{array}
  \end{equation*}
\end{definition}

Ein Schätzwert ist das Ergebnis einer konkreten Berechnung, eine Zahl. Sie
entsteht durch das Einsetzen konkreter Daten in einen Schätzer: $T_j (\omega) =
  t_j (x_1, \dots, x_n)$ und liefert damit einen Wert für genau einen Parameter.
\subsection{Eigenschaften von Schätzern}
Sei $T$ ein Schätzer.
\begin{itemize}
  \item $T$ ist erwartungstreu, falls $E_\vt[T] = \vt$ gilt. $T$ schätzt
        im Mittel also richtig.
  \item Bias $:= E_\vt[T] - \vt$. Ein erwartungstreuer Schätzer hat also keinen Bias.
  \item Mittlere Quadratische Schätzfehler $MSE_\vt[T] := E_\vt[ {(T - \vt)}^2]$.
  \item Eine Folge $T^{ (n)}$ von Schätzern heisst konsistent für $\vt$, falls $T^{
              (n)}$ für $n \ra \infty$ in $P_\vt$-Wahrscheinlichkeit gegen $\vt$ konvergiert,
        d.h. für jedes $\vt \in \varTheta$ gilt:
        \begin{align*}
          \lim_{n \ra \infty} P_\vt \left[ \abs{T^{ (n)} - \vt} > \varepsilon \right] = 0
        \end{align*}
\end{itemize}
\BoxStart{}
\subsection{Beispiel: Erwartungstreuer Schätzer}
Seien $X_1, \ldots, X_n$ unabhängige, identisch verteilte Zufallsvariablen mit $X_i \sim \mathcal{U}([\theta - 1, \theta]) unter \mathbb{P}_\theta$
wobei $\theta \in \mathbb{R}$. Wir betrachten den Schätzer
\[T_1^{(n)} := \frac{1}{n} \cdot \sum_{i = 1}^n X_i + \frac{1}{2}\]
Sind Schätzer erwartungstreu?

Sei $\theta \in \mathbb{R}$ fixiert. Aus der Gleichverteilung folgt, dass

\begin{align*}
  \mathbb{E}_{\theta}[{T(n)}_1] & = \left(\frac{1}{n} \sum_{i=1}^{n} \mathbb{E}_{\theta}[X_i]\right) + \frac{1}{2} \\
                                & = \mathbb{E}_{\theta}[X_1] + \frac{1}{2} = \theta - \frac{1}{2} + \frac{1}{2}    \\
                                & = \theta
\end{align*}
Somit folgt, dass der Schätzer ${T(n)}_1$ erwartungstreu ist.

\BoxEnd{}
\subsection{Maximum-Likelihood Methode}
(Analog im diskreten Fall.) In einem Modell $P_\vt$ sind die Zufallsvariablen
$\zufallsvariablen$ stetig mit einer gemeinsamen Dichtefunktion
$f (x_1, \dots, x_n, \vt)$. Oft sind die $X_i$ i.i.d. und man erhält:
\begin{align*}
  f (x_1, \dots, x_n, \vt) & = P[X_1 = x_1, \dots, X_n = x_n] \\
                           & = \prod_{i = 1}^n f_X (x_i, \vt)
\end{align*}
Wir nehmen nun an, dass die Daten die wir erhalten haben sehr
Wahrscheinlich sind und versuchen nun folgende Likelihood funktion
zu Maximieren durch Anpassungen an $\vt$:
\begin{align*}
  L (x_1, \dots, x_n; \vt)      & := f (x_1, \dots, x_n; \vt)      \\
  \log L (x_1, \dots, x_n; \vt) & := \log f (x_1, \dots, x_n; \vt)
\end{align*}
letzteres kann bei Produkt zu Summe umwandlung hilfreich sein.
\BoxStart{}
\subsection{Beispiel: Maximum Likelyhood-Funktion}
Sei $\Theta = [0, 1]$. Wir betrachten die Modellfamilie $ {P_\theta}_{\theta \in \Theta}$, wobei $X_1, \ldots, X_n$ unter $\mathbb{P}_\theta$ unabhängig und identisch verteilt sind mit $X_1 \sim \text{Geom} (\theta)$. Was ist die Likelihood-Funktion $L (x_1, \ldots, x_n; \theta)$ für $x_1, \ldots, x_n \in \{1, 2, \ldots\}$?
\begin{align*}
  L (x_1, \ldots, x_n; \theta) & =  (P_\theta) [X_1 = x_1,\ldots , X_n = x_n]              \\
                               & =\prod_{i = 1}^n \mathbb{P}_\theta[X_i = x_i]             \\
                               & = \theta^n \cdot  {(1 - \theta)}^{x_1 + \ldots + x_n - n}
\end{align*}
\\
Was ist der Maximum-Likelihood-Schätzer $T_{\text{ML}}$ für $\theta$?

\[
  n \cdot \log (\theta) +  (x_1 + \ldots + x_n - n) \cdot \log (1 - \theta)
\]

Wir setzen nun die Ableitung der log-Likelihood-Funktion nach $\theta$ gleich
$0$ und erhalten:

\begin{align*}
   & \frac{n}{\theta} - \frac{x_1 + \ldots + x_n - n}{1 - \theta} = 0               \\
   & \Longleftrightarrow n - n\theta =  (x_1 + \ldots + x_n) \cdot \theta - n\theta \\
   & \Longleftrightarrow \theta = \frac{n}{x_1 + \ldots + x_n}                      \\
   & = \frac{n}{X_1 + \ldots + X_n}
\end{align*}

\BoxEnd{}

\begin{definition}{Normalverteile Stichprobe}
  Sei $\zufallsvariablen$ i.i.d. $\Normalverteilt$-verteilt mit unbekannten
  Parametern $\vt = (\mu, \sigma^2)$. Damit berechnen wir mit der $\log$ max
  likelihood funktion Ableitungen setzen diese zu $0$ und bekommen:
  \begin{align*}
    T_1 & = \frac{1}{n} \Sn X_i = \overline{X}_n     \\
    T_2 & = \frac{1}{n} \Sn {X_1 - \overline{X}_n}^2
  \end{align*}
  möchten wir aber noch, dass der Schätzer erwartungstreu wird,
  so wählen wir für $T_2 = S^2$:
  \begin{align*}
    S^2 = \frac{1}{n-1} \Sn  {(X_i - \overline{X}_n)}^2
  \end{align*}
\end{definition}
\subsection{Normalverteile Stichproben}
Seien $\zufallsvariablen$ i.i.d. $\sim \Normalverteilt$. Dann gilt:
\begin{itemize}
  \item $\overline{X}_n \sim \mathcal{N} (\mu, \frac{\sigma^2}{n})$
        und $\frac{\overline{X}_n - \mu}{\sigma / \sqrt{n}} \sim \Standardnormalverteilt$.
  \item $\frac{n-1}{\sigma^2} S^2 = \left( \frac{1}{\sigma^2} \Sn  {(X_i - \overline{X}_n)}^2 \right) \sim \mathcal{X}^2_{n-1}$
  \item $\overline{X}_n$ und $S^2$ sind unabhängig
  \item $\frac{\overline{X}_n - \mu}{S / \sqrt{n}} = \frac{ \frac{\overline{X}_n - \mu}{\sigma / \sqrt{n}} }{S / \sigma} = \frac{ \frac{\overline{X}_n - \mu}{\sigma / \sqrt{n}} }{\sqrt{\frac{1}{n-1} \frac{n-1}{\sigma^2} S^2}} \sim t_{n-1}$
\end{itemize}
